{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Imports the Google Cloud client library\n",
    "from google.cloud import language\n",
    "from google.cloud.language import enums\n",
    "from google.cloud.language import types\n",
    "\n",
    "import asyncio\n",
    "from aiohttp import ClientSession\n",
    "from functools import partial\n",
    "from aiohttp import ClientConnectorError\n",
    "import re\n",
    "from itertools import chain\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Instantiates a client\n",
    "client = language.LanguageServiceClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat1 = pd.read_pickle(\"../data/elmondo_es.pkl\")\n",
    "dat2 = pd.read_pickle(\"../data/elmondo_es_eco.pkl\")\n",
    "dat3 = pd.read_pickle(\"../data/elmondo_es_sp.pkl\")\n",
    "dat4 = pd.read_pickle(\"../data/cnn_es.pkl\")\n",
    "dat = pd.concat([dat1, dat2, dat3, dat4], axis=0, ignore_index=True)\n",
    "del dat1, dat2, dat3, dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>keyfacts</th>\n",
       "      <th>content</th>\n",
       "      <th>tags</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Una jueza del Tribunal Supremo suspende parcia...</td>\n",
       "      <td>[ Decidió atender a los grupos conservadores y...</td>\n",
       "      <td>El martes, antes de presidir la fiesta de fin ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2014-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'La revolución cubana sigue sin compromisos co...</td>\n",
       "      <td>[ 'Jamás hemos cedido ni cederemos ante agresi...</td>\n",
       "      <td>El presidente Raúl Castro reveló que se está i...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2014-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>La NSA trabaja en un ordenador cuántico capaz ...</td>\n",
       "      <td>[ La información proviene de los documentos de...</td>\n",
       "      <td>La Agencia de Seguridad Nacional (NSA) trabaja...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2014-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Último adiós a la ex Miss Venezuela Mónica Spe...</td>\n",
       "      <td>[ Mónica Spear y su marido fueron asesinados e...</td>\n",
       "      <td>Esta semana Venezuela ha recibido una noticia ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2014-01-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Michoacán pone en jaque al Gobierno de Peña Nieto</td>\n",
       "      <td>[ El Gobierno envía más policías y militares y...</td>\n",
       "      <td>La situación en el Estado mexicano de Michoacá...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2014-01-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  \\\n",
       "0  Una jueza del Tribunal Supremo suspende parcia...   \n",
       "1  'La revolución cubana sigue sin compromisos co...   \n",
       "2  La NSA trabaja en un ordenador cuántico capaz ...   \n",
       "3  Último adiós a la ex Miss Venezuela Mónica Spe...   \n",
       "4  Michoacán pone en jaque al Gobierno de Peña Nieto   \n",
       "\n",
       "                                            keyfacts  \\\n",
       "0  [ Decidió atender a los grupos conservadores y...   \n",
       "1  [ 'Jamás hemos cedido ni cederemos ante agresi...   \n",
       "2  [ La información proviene de los documentos de...   \n",
       "3  [ Mónica Spear y su marido fueron asesinados e...   \n",
       "4  [ El Gobierno envía más policías y militares y...   \n",
       "\n",
       "                                             content tags        time  \n",
       "0  El martes, antes de presidir la fiesta de fin ...   []  2014-01-02  \n",
       "1  El presidente Raúl Castro reveló que se está i...   []  2014-01-02  \n",
       "2  La Agencia de Seguridad Nacional (NSA) trabaja...   []  2014-01-03  \n",
       "3  Esta semana Venezuela ha recibido una noticia ...   []  2014-01-10  \n",
       "4  La situación en el Estado mexicano de Michoacá...   []  2014-01-14  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37702, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def has_proper_mentions(mentions):\n",
    "    return np.any([mention.type == 1 for mention in mentions])\n",
    "\n",
    "def process_response(response):\n",
    "    entities = response.entities\n",
    "    return [{'entity_name': ent.name,\n",
    "             'entity_type': entity_type[ent.type], \n",
    "            'mentions': list(set(mention.text.content\n",
    "                        for mention in ent.mentions if mention.type == 1))} \n",
    "            for ent in entities if has_proper_mentions(ent.mentions)]\n",
    "\n",
    "entity_type = ('UNKNOWN', 'PERSON', 'LOCATION', 'ORGANIZATION',\n",
    "               'EVENT', 'WORK_OF_ART', 'CONSUMER_GOOD', 'OTHER')\n",
    "\n",
    "mention_type = ('TYPE_UNKNOWN', 'PROPER', 'COMMON')\n",
    "\n",
    "async def get_entity_data(idx, session):\n",
    "    attempts = 0\n",
    "    while attempts < 3:\n",
    "        try:\n",
    "            # The text to analyze\n",
    "            text = \"\\n\".join(dat['keyfacts'].iloc[idx]) + '\\n\\n' + dat['content'].iloc[idx]\n",
    "\n",
    "            document = types.Document(\n",
    "                content=text,\n",
    "                type=enums.Document.Type.PLAIN_TEXT)\n",
    "\n",
    "            # Detects the sentiment of the text\n",
    "            response = client.analyze_entities(document=document)\n",
    "            out = process_response(response)\n",
    "            return idx, out\n",
    "        except ClientConnectorError:\n",
    "            attempts += 1\n",
    "#             print(\"Connector error occurred!\")\n",
    "    if attempts == 3:\n",
    "        print(\"Connector error occurred! Connection Failed!\")\n",
    "        return idx, None\n",
    "\n",
    "async def gather_results(curr, step):\n",
    "    \"\"\"Launch scrape tasks and collect results\"\"\"\n",
    "    tasks = []\n",
    "    async with ClientSession() as session:\n",
    "        for idx in range(curr, curr + step):\n",
    "            task = asyncio.ensure_future(get_entity_data(idx, session))\n",
    "            tasks.append(task)\n",
    "\n",
    "        responses = await asyncio.gather(*tasks)\n",
    "        # you now have all response bodies in this variable\n",
    "        return responses\n",
    "\n",
    "\n",
    "def process_df(future, curr, step):\n",
    "    \"\"\"Save scrape results in json files\"\"\"\n",
    "    cache = {k: v for k, v in future.result()}\n",
    "#     cache = future.result()\n",
    "    if len(cache) == 0:\n",
    "        raise RuntimeError(\"Empty response!\")\n",
    "    else:\n",
    "        json.dump(cache, open(\"../data/mondo_entities/entities_{0}_{1}.json\".format(curr, curr + step), \"w\"))\n",
    "#         print(cache)\n",
    "        print(\"got it! ({0}, {1})\".format(curr, curr + step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from 37700 to 37702\n",
      "got it! (37700, 37702)\n"
     ]
    }
   ],
   "source": [
    "start = 37700\n",
    "end = 37702\n",
    "step = 100\n",
    "abandoned = []\n",
    "\n",
    "for curr in range(start, end, step):\n",
    "    inc = min(step, end - start)\n",
    "    print(\"loading data from {0} to {1}\".format(curr, curr + inc))\n",
    "    loop = asyncio.get_event_loop()\n",
    "    future = asyncio.ensure_future(gather_results(curr, inc))\n",
    "    future.add_done_callback(partial(process_df, curr=curr, step=inc))\n",
    "    loop.run_until_complete(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_es = dat.to_pickle(\"../data/full_es.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ENTITY_ROOT = \"../data/mondo_entities/\"\n",
    "fn = os.listdir(ENTITY_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "entities = dict()\n",
    "for file in fn:\n",
    "    with open(os.path.join(ENTITY_ROOT, file), \"r\") as f:\n",
    "        entities.update(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(entities, open(\"../data/es_processed_entities.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [py36]",
   "language": "python",
   "name": "Python [py36]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Model Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improved Attentive Reader\n",
    "A thorough examination of the cnn/daily mail reading comprehension task\n",
    "\n",
    "Chen, Danqi, Jason Bolton, and Christopher D. Manning. \"A thorough examination of the cnn/daily mail reading comprehension task.\" arXiv preprint arXiv:1606.02858 (2016).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "R_i = \\phi_{RNN}^C(emb(C_i))[:]\n",
    "$$$$\n",
    "r = \\phi_{RNN}^Q(emb(Q))[-1]\n",
    "$$$$\n",
    "a_i = Softmax(R_i^T M r)\n",
    "$$$$\n",
    "u = \\sum_i a_i R_i\n",
    "$$$$\n",
    "o = Softmax(\\phi_{Linear}(u))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modified Model Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shared Embedding Reader\n",
    "$$\n",
    "\\phi(\\cdot)=\\phi^{RNN}((\\phi^{word\\_emb_{L_1, L_2}}(\\cdot) + \\phi^{entity\\_emb}(\\cdot))\n",
    "$$$$\n",
    "R_i^{(j)}[:]=\\phi(C_i^{(j)})[:]\n",
    "$$$$\n",
    "r_i^{(j)}=\\phi(Q_i^{(j)})[-1]\n",
    "$$$$\n",
    "\\gamma(R, r) = Softmax[Linear(r, \\sigma(R, r) \\odot R)]\n",
    "$$\n",
    "\n",
    "Shared embedding mechanism: WIP\n",
    "\n",
    "Goal:\n",
    "$$\n",
    "argmax_{\\Theta_\\phi, \\Theta_\\gamma} logP(A|Q, C, \\Theta_\\phi, \\Theta_\\gamma)\n",
    "$$\n",
    "\n",
    "#### Reader / Language Discriminator\n",
    "$$\n",
    "\\phi_i(\\cdot)=\\phi_i^{RNN}((\\phi_i^{word\\_emb}(\\cdot) + \\phi^{entity\\_emb}(\\cdot))\n",
    "$$$$\n",
    "R_i^{(j)}[:]=\\phi_i(C_i^{(j)})[:]\n",
    "$$$$\n",
    "r_i^{(j)}=\\phi_i(Q_i^{(j)})[-1]\n",
    "$$$$\n",
    "\\gamma(R, r) = Softmax[Linear(r, \\sigma_i(R, r) \\odot R)]\n",
    "$$$$\n",
    "\\delta(\\cdot) = \\delta^{MLP}(\\cdot)\n",
    "$$\n",
    "\n",
    "The joint goal can be represented as:\n",
    "$$\n",
    "argmax_{\\Theta_\\phi, \\Theta_\\gamma} [logP(A|Q, C, \\Theta_\\phi, \\Theta_\\gamma)\n",
    "+ \\alpha \\cdot log P(\\lnot L|Q, C,\\Theta_\\phi, \\Theta_\\delta)]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Collection Method and Description\n",
    "\n",
    "#### English QA data:\n",
    "https://github.com/deepmind/rc-data/ (Hermann et al., NIPS 2015)\n",
    "\n",
    "Use CNN part of the dataset.\n",
    "Story - Question - Answer tuples, anonymised with coreference resolution.\n",
    "\n",
    "#### Spanish QA data:\n",
    "Collected from www.elmondo.es (via cached links on Wayback Machine) and processed to fit the format of the CNN dataset. Anonymised through named entity recognition.\n",
    "\n",
    "#### English and Spanish word embeddings:\n",
    "https://github.com/facebookresearch/fastText/blob/master/pretrained-vectors.md\n",
    "\n",
    "(P. Bojanowski*, E. Grave*, A. Joulin, T. Mikolov, Enriching Word Vectors with Subword Information)\n",
    "\n",
    "300 dimension word vectors trained on Wikipedia text.\n",
    "\n",
    "#### Word alignment dictionary:\n",
    "http://opus.lingfil.uu.se/download.php?f=EUbookshop%2Fdic%2Fen-es.dic\n",
    "\n",
    "(Raivis Skadiņš, J�rg Tiedemann, Roberts Rozis and Daiga Deksne (2014): Billions of Parallel Words for Free, In Proceedings of LREC 2014, Reykjavik, Iceland)\n",
    "\n",
    "EU Bookshop parallel corpus dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Method | English (best) | Spanish (best) | Bilingual (best) | English (avg.) | Spanish (avg.) | Bilingual (avg.) |\n",
    "|-----|-----|-----|-----|\n",
    "| Individual embeddings | 0 | 0 | 0 | 0 | 0 | 0 |\n",
    "| Mapped embeddings | 0 | 0 | 0 | 0 | 0 | 0 |\n",
    "| Adversarial training | 0 | 0 | 0 | 0 | 0 | 0 |\n",
    "| Mapped embeddings / Adv. Training | 0 | 0 | 0 | 0 | 0 | 0 |\n",
    "\n",
    "\n",
    "| Mapping Method | English | Spanish | Bilingual |\n",
    "|-----|-----|-----|-----|\n",
    "| None | 0 | 0 | 0 |\n",
    "| Unconstrained | 0 | 0 | 0 |\n",
    "| Normalised | 0 | 0 | 0 |\n",
    "| Normalised + mean shift | 0 | 0 | 0 |\n",
    "\n",
    "#### Training Curve Comparison\n",
    "\n",
    "#### Dictionary Size vs Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [py36]",
   "language": "python",
   "name": "Python [py36]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
